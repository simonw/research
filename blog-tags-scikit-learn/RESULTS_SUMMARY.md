# Blog Tag Prediction - Results Summary

## Quick Overview

This project successfully implemented and compared 4 different machine learning models to predict tags for 816 untagged blog entries using 2,314 tagged entries as training data.

## Winner: LinearSVC

**TF-IDF + LinearSVC** achieved the best overall performance:

- **F1 Score:** 0.6791 (highest)
- **Precision:** 0.8543
- **Recall:** 0.5636 (highest)
- **Training Time:** 3.84 seconds

## All Models Performance

| Rank | Model | F1 Score | Precision | Recall | Training Time |
|------|-------|----------|-----------|---------|---------------|
| 1 | LinearSVC | 0.6791 | 0.8543 | 0.5636 | 3.84s |
| 2 | Naive Bayes | 0.5604 | 0.6134 | 0.5159 | 3.35s |
| 3 | Random Forest | 0.5231 | 0.9011 | 0.3685 | 33.71s |
| 4 | Logistic Regression | 0.4579 | 0.9194 | 0.3049 | 4.62s |

## Key Insights

1. **Best Overall:** LinearSVC provides the best balance of precision and recall
2. **Highest Precision:** Logistic Regression (92%) and Random Forest (90%) are most conservative
3. **Fastest:** Naive Bayes trains in just 3.35 seconds
4. **Slowest:** Random Forest takes 33.71 seconds but offers good precision

## Sample Predictions

### Entry: "Netscape 4 is 5 years old"

- **LinearSVC:** programming, jeffrey-zeldman, startups
- **Naive Bayes:** css, mozilla, mark-pilgrim
- **Random Forest:** google, apis, mark-pilgrim
- **Logistic Regression:** quora, python, javascript

## Dataset Statistics

- Total blog entries: 3,223
- Tagged entries (training): 2,314
- Untagged entries (predictions): 816
- Unique tags: 158 (filtered to â‰¥10 occurrences)
- Text features: 3,000-5,000 TF-IDF features

## Output Files

All results are available in JSON format:

1. `results_logistic_regression.json` - 909 KB
2. `results_naive_bayes.json` - 915 KB
3. `results_random_forest.json` - 905 KB
4. `results_linear_svc.json` - 924 KB
5. `prepared_data.json` - 12 MB
6. `visualization.html` - Interactive visualization

## How to Use

### Run All Models

```bash
python3 run_all_models.py
```

### Run Individual Model

```bash
python3 model_linear_svc.py
```

### View Results

Open `visualization.html` in a web browser to see interactive visualizations and compare models.

## Recommendations

For production use, we recommend **LinearSVC** because it:
- Achieves the highest F1 score (0.68)
- Has the best recall (56%) - finds more relevant tags
- Maintains strong precision (85%)
- Trains quickly (< 4 seconds)
- Scales well to high-dimensional text data

## Next Steps

Potential improvements:
1. Tune hyperparameters with grid search
2. Try ensemble methods (combine multiple models)
3. Add more features (post length, date, etc.)
4. Use deep learning models (BERT, transformers)
5. Implement active learning for uncertain predictions
